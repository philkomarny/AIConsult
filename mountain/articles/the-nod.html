<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Nod — Phil Komarny</title>
    <meta name="description" content="AI writes the bare minimum and calls it done. Humans break the fourth wall, crack jokes, betray your senses. Five sisters taught me the difference.">
    <meta property="og:title" content="The Nod — Phil Komarny">
    <meta property="og:description" content="What AI does that it shouldn't. What humans do that AI can't. Five Sisters of the Sacred Heart taught me to tell the difference.">
    <meta property="og:type" content="article">
    <meta name="twitter:card" content="summary">
    <link rel="icon" type="image/png" href="../images/mtlogo.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,400;0,600;0,700;1,400&family=Outfit:wght@300;400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <div class="sky">
        <div class="stars"></div>
        <div class="cygnus">
            <span class="star deneb"></span>
            <span class="star sadr"></span>
            <span class="star gienah-cyg"></span>
            <span class="star delta-cyg"></span>
            <span class="star albireo"></span>
        </div>
        <div class="leo">
            <span class="star regulus"></span>
            <span class="star denebola"></span>
            <span class="star algieba"></span>
            <span class="star zosma"></span>
            <span class="star ras-elased"></span>
            <span class="star adhafera"></span>
        </div>
        <div class="atmosphere"></div>
    </div>

    <div class="mountains">
        <svg class="mountain-range range-far" viewBox="0 0 1440 500" preserveAspectRatio="none">
            <path d="M0,500 L0,320 L80,280 L160,320 L280,220 L400,280 L520,180 L640,240 L760,140 L880,200 L1000,120 L1120,180 L1240,100 L1360,160 L1440,120 L1440,500 Z" fill="var(--mountain-far)"/>
        </svg>
        <svg class="mountain-range range-mid" viewBox="0 0 1440 500" preserveAspectRatio="none">
            <path d="M0,500 L0,380 L100,340 L180,360
                     L280,320 L380,340
                     L480,300 L560,280
                     L640,240 L700,180 L750,120 L800,70 L850,50 L900,70 L950,110 L1020,180 L1100,240
                     L1180,280 L1260,260 L1340,290 L1440,250 L1440,500 Z" fill="var(--mountain-mid)"/>
            <path d="M750,120 L800,70 L850,50 L900,70 L950,110 L1020,180 L980,190 L920,130 L850,100 L800,120 L750,120 Z" fill="rgba(240,244,248,0.15)"/>
        </svg>
        <svg class="mountain-range range-near" viewBox="0 0 1440 500" preserveAspectRatio="none">
            <path d="M0,500 L0,380 L120,340 L240,370 L360,320 L480,360 L600,300 L720,350 L840,290 L960,340 L1080,280 L1200,330 L1320,290 L1440,320 L1440,500 Z" fill="var(--mountain-near)"/>
        </svg>
        <div class="tree-line"></div>
    </div>

    <main class="page">
        <header class="page-header">
            <a href="../thoughts.html" class="back-link">← Field Notes</a>
            <span class="page-title">February 2026</span>
        </header>

        <article class="article-content">
            <h1>The Nod</h1>
            <p class="article-meta">What AI does that it shouldn't. What humans do that <span class="gradient-text">AI can't.</span></p>

            <img src="../images/the-nod.svg" alt="A bridge of light connecting two different worlds of understanding" class="article-inline-image" loading="lazy">

            <p>I sat in a board meeting this week at the university I serve. Around the table were administrators, faculty, finance people, and five Sisters of the Sacred Heart. Each of them has given a lifetime to education. Each of them loves this institution with a depth that most people in tech will never understand about anything. And I was about to present my AI work to all of them.</p>

            <p>Here's what I knew walking in: if I lost the sisters, I lost the room. Not because they hold the most votes or control the budget, but because they hold the moral center. When they understand something and believe in it, everyone else feels it. And when they don't, everyone feels that too. So I needed to get this right. And getting it right meant understanding something that most people in technology have never stopped to consider: <span class="gradient-text">what makes human communication land, and why AI keeps missing.</span></p>

            <p>I'd been thinking about this for weeks before the meeting. Not about what to say, but about how to say it. Because I'd been reading a lot of AI-generated content lately, the kind that companies are pumping out by the metric ton, and something about it had been bothering me. It was all correct. It was all competent. And none of it made me feel a single thing. I started making a list of why.</p>

            <p>The first problem is the bare minimum. AI doesn't write; it completes. Give it a prompt and it will produce exactly enough words to satisfy the request, but never a syllable more than the assignment requires. There's no excess, no overflow, no moment where the writer got so absorbed in an idea that they forgot they were supposed to be wrapping up. Human writing has that. The best human writing is full of it. The paragraph that didn't need to be there but changes everything. The aside that reveals more than the main argument. AI doesn't do asides. It does deliverables.</p>

            <p>Then there's the abstraction trap. AI lives in abstraction the way fish live in water: it doesn't know it's there. Every concept gets described at thirty thousand feet. "Innovation drives transformation." "Collaboration enables success." These sentences are technically true and experientially empty. They scan like wisdom and dissolve on contact. A sister who has spent sixty years teaching children doesn't think in abstractions. She thinks in the face of a specific student on a specific afternoon when understanding finally broke through. That's not abstraction. <span class="gradient-text">That's the thing itself.</span></p>

            <p>AI is also pathologically harmless. Every edge gets sanded. Every opinion gets hedged. Every sentence that might make someone uncomfortable gets run through an internal filter until it comes out warm, balanced, and saying nothing. The result reads like a press release from an organization that has been sued too many times. But the sisters didn't give their lives to an institution because it was harmless. They gave their lives because it mattered enough to be dangerous. Faith is dangerous. Commitment is dangerous. Telling a room full of powerful people that they need to change is dangerous. <span class="gradient-text">Harmlessness is just cowardice with better punctuation.</span></p>

            <p>And then there's what I started calling sensory betrayal, the moment in good writing when you feel something in your body. Your stomach drops. The hair on your arms stands up. You inhale sharply because a sentence landed somewhere below your conscious mind. AI never does this because it doesn't have a body and it doesn't know you have one either. It writes to your intellect and stops there. But the sisters don't live in their intellects. They live in a tradition that kneels, that sings, that breaks bread, that anoints the dying with oil and the living with water. Their entire framework for understanding the world is embodied. If I was going to reach them, I needed to write something they could feel.</p>

            <p>The last two problems are related. AI forces callbacks, those mechanical transitions that exist only to remind you of the thesis. "As mentioned earlier." "Returning to the point above." These are the literary equivalent of a GPS recalculating. They don't trust the reader to hold the thread. And that lack of trust is the deepest problem of all. AI doesn't know who it's writing for, so it writes for everyone, which means it writes for no one. It hedges, it over-explains, it qualifies every claim as if the reader might be hostile or stupid or both. Good writing does the opposite. Good writing says: I know who you are. I know what you already understand. <span class="gradient-text">I trust you to meet me here.</span></p>

            <p>That was my list of what AI does wrong. Six failures, each one a kind of disrespect. But knowing what's broken doesn't tell you what works. So I started watching what real humans do when they communicate in a way that actually lands, and I realized the sisters had been teaching me this all along.</p>

            <p>They break the fourth wall. Not in a dramatic, theatrical way, but in the way that the best teachers always do. They stop mid-sentence and say, "You know what I mean." They look at you and you understand that the words are not a performance but a conversation, even when you're the only one sitting in the audience. When I present, the moment I stop delivering information and start talking <em>to</em> someone, I can feel the room shift. The fourth wall is the distance between a lecture and a conversation, and the sisters demolish it without even trying because they never built it in the first place.</p>

            <p>They make internal callbacks. Not the forced, mechanical kind that AI uses, but the organic kind where a phrase from the first minute resurfaces in the last minute and suddenly means something different. When a sister references a prayer from morning chapel during an afternoon discussion about enrollment strategy, she's not being tangential. She's showing you that everything is connected, that the morning and the afternoon are part of the same fabric. <span class="gradient-text">The callback isn't a device. It's a worldview.</span></p>

            <p>They crack jokes to relieve tension. Not jokes that deflect or diminish, but the kind that acknowledge the weight of the room and give everyone permission to breathe. I've watched a sister defuse a tense budget discussion with a single dry observation that made every person at the table laugh and then lean back in. That release isn't a distraction from serious work. It's what makes serious work sustainable. AI doesn't know how to be funny because humor requires knowing exactly when someone needs relief, and you can only know that if you're paying attention to what they're carrying.</p>

            <p>They switch registers naturally. One moment they're discussing capital expenditures, the next they're quoting Augustine, the next they're telling you about a student who showed up at their door at midnight. These aren't jarring transitions. They're seamless because the person making them has a mind that holds all of those registers simultaneously. AI writes in one register per prompt. It can be formal or informal, technical or poetic, but it can't be all of them in the same paragraph the way a human can, the way you do when you're talking to someone you trust.</p>

            <p>And they become obsessively, almost irrationally detail-oriented. Not about everything. About the things that matter. A sister will remember the exact date a student's parent died. She'll recall the color of the flowers at a ceremony forty years ago. She'll correct you on a name you mispronounced once, three meetings back. This isn't pedantry. It's love expressed as attention. <span class="gradient-text">The detail is the proof that you were there.</span></p>

            <p>So when I stood up to present to the board, I had all of this in my head. And I looked at nobody but the sisters.</p>

            <p>Not the CFO, not the provost, not the other board members. Just them. I explained each concept in their language, mapping neural networks to the communion of saints, deep learning to contemplative prayer, a language model trained on the whole of human text to the Word made flesh. But I didn't just translate vocabulary. I broke the fourth wall. I looked Sister in the eye and said, "You already know this." I let a callback from the chapel reading that morning surface in my explanation of generative AI. I made a joke about being the only person in the room who needed a manual for things the Holy Spirit handles automatically. I switched from technical language to theological language to plain language and back, because that's how real people actually think. And I used details. Specific details. The name of the student who had used AI to write her first research paper. The date of the faculty workshop where a seventy-year-old professor built his first chatbot. The look on his face when it worked.</p>

            <p>Before I moved to the next concept, I waited. Not for a question or a comment, just for the nod. A simple movement of the head and a small smile. <em>I understand. Go on.</em></p>

            <p>That was my signal. Every single time.</p>

            <p>Deep learning mapped to the interior castle of St. Teresa of Avila, the many mansions of deepening prayer. <em>Nod.</em> Transformers described as the Transfiguration, the breakthrough moment where something hidden is suddenly revealed. <em>Nod.</em> A language model trained on the whole of human text to make knowledge accessible. The Word made flesh. <span class="gradient-text"><em>Nod. Smile.</em></span></p>

            <p>When it was over, the sisters didn't just understand AI. They saw themselves in it. They saw their life's work reflected in a new technology, and that changed the entire conversation from fear to curiosity, from resistance to recognition. Not because I'd given a good presentation. Because I'd given a human one. One that did the things humans do and refused to do the things AI does. One that trusted them enough to skip the disclaimers and speak directly. One that earned every nod.</p>

            <p>Here's what I keep thinking about since that meeting. Everyone in technology is worried about AI replacing human communication. They should be worried about human communication replacing itself with AI habits. We're already starting to write like the machines. Safe, abstract, harmless, disembodied, distrustful of the reader, mechanically structured. Every time we let AI draft our emails, our presentations, our strategy documents, we're training ourselves to accept a flattened version of what communication can be. <span class="gradient-text">The danger isn't that AI will learn to write like us. It's that we'll forget we ever wrote differently.</span></p>

            <p>The nod from a Sister of the Sacred Heart meant more to me than any standing ovation from a tech conference ever has. Because a standing ovation means you performed well. A nod means you were understood. And there is a universe of difference between the two.</p>

            <p>The machines will keep getting better at the bare minimum. Let them. The rest of us have different work to do. Break the fourth wall. Make callbacks that mean something. Crack the joke that lets the room breathe. Switch registers like a human who contains multitudes. Notice the details that prove you were paying attention. Write like you have a body and your reader has one too. Trust the person in front of you to meet you where you are.</p>

            <p>And when they nod, you'll know. Not because an algorithm confirmed engagement. <span class="gradient-text">Because a person did.</span></p>

            <p class="article-cta">Ready to find your translation? <a href="../contact.html">Let's talk</a> or join the conversation in <a href="https://discord.gg/GVnnw4xf" target="_blank" rel="noopener noreferrer">Discord</a>.</p>
        </article>
    </main>

    <script src="../main.js"></script>
</body>
</html>
